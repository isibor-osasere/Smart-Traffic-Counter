{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856b5699-85a0-428c-970c-3b4c1a89979a",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcece32-9712-4181-8d6a-9a7b8f69c790",
   "metadata": {},
   "source": [
    "### YOLOv8 vehicle counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0203557-aa77-49a7-9fb3-e8c2afb78a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2, time\n",
    "\n",
    "def run_yolov8_tracking_with_counter(video_source, model_path):\n",
    "    \"\"\"\n",
    "    Run vehicle detection, tracking, and counting using YOLOv8 with class names.\n",
    "    Args:\n",
    "        video_source: Path to the video file or webcam index (e.g., 0 for default webcam).\n",
    "        model_path: Path to YOLOv8 model (e.g., \"yolov8n.pt\").\n",
    "    \"\"\"\n",
    "    # Load YOLOv8 model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Open the video source\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "        print('Error: Unable to open video source.')\n",
    "        return\n",
    "\n",
    "    # Vehicle counters and helper variables\n",
    "    entered_vehicle_ids = []\n",
    "    exited_vehicle_ids = []\n",
    "\n",
    "    # Map of vehicle class IDs to names\n",
    "    class_names = model.names\n",
    "    vehicle_class_ids = [1, 2, 3, 5, 7]  # IDs for bicycle, car, motorcycle, bus, truck\n",
    "    vehicle_entry_count = {class_names[cls]: 0 for cls in vehicle_class_ids}\n",
    "    vehicle_exit_count = {class_names[cls]: 0 for cls in vehicle_class_ids}\n",
    "\n",
    "    # Entry and exit lines\n",
    "    entry_line = {'x1': 160, 'y1': 558, 'x2': 708, 'y2': 558}\n",
    "    exit_line = {'x1': 1155, 'y1': 558, 'x2': 1718, 'y2': 558}\n",
    "    offset = 20\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit the loop if no more frames\n",
    "\n",
    "        start_time = time.time()  # Start timer for FPS calculation\n",
    "\n",
    "        # Perform detection and tracking\n",
    "        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")  # Use built-in ByteTrack tracker\n",
    "\n",
    "        # Ensure results contain boxes\n",
    "        if results and results[0].boxes is not None:\n",
    "            for box in results[0].boxes:\n",
    "                # Extract bounding box coordinates, class ID, confidence, and track ID\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy().flatten())  # Bounding box coordinates\n",
    "                cls = int(box.cls.cpu().numpy().item())  # Class ID\n",
    "                conf = float(box.conf.cpu().numpy().item())  # Confidence score\n",
    "                track_id = int(box.id.cpu().numpy().item()) if box.id is not None else None  # Track ID (if available)\n",
    "\n",
    "                # Get the class name\n",
    "                class_name = class_names[cls]\n",
    "\n",
    "                # Calculate the center of the bounding box\n",
    "                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "                # Draw bounding box and label\n",
    "                color = (0, 255, 0)  # Green color for vehicles\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                #label = f\"ID: {track_id}, Class: {class_name}, Conf: {conf:.2f}\"\n",
    "                label = f\"{class_name}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                # Count vehicles crossing entry line\n",
    "                if entry_line['x1'] <= center_x <= entry_line['x2'] and entry_line['y1'] <= center_y <= entry_line['y1'] + offset:\n",
    "                    if track_id not in entered_vehicle_ids and cls in vehicle_class_ids:\n",
    "                        vehicle_entry_count[class_name] += 1\n",
    "                        entered_vehicle_ids.append(track_id)\n",
    "\n",
    "                # Count vehicles crossing exit line\n",
    "                if exit_line['x1'] <= center_x <= exit_line['x2'] and exit_line['y1'] - offset <= center_y <= exit_line['y1']:\n",
    "                    if track_id not in exited_vehicle_ids and cls in vehicle_class_ids:\n",
    "                        vehicle_exit_count[class_name] += 1\n",
    "                        exited_vehicle_ids.append(track_id)\n",
    "\n",
    "        # Draw overlays for entry and exit counters\n",
    "        y_pos = 100\n",
    "        cv2.putText(frame, \"EXIT\", (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 250), 3)\n",
    "        for idx, (cls_name, count) in enumerate(vehicle_entry_count.items()):\n",
    "            y_pos = 150 + idx * 30\n",
    "            cv2.putText(frame, f\"{cls_name}: {count}\", (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        y_pos = 100\n",
    "        cv2.putText(frame, \"ENTRY\", (1710, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 250), 3)\n",
    "        for idx, (cls_name, count) in enumerate(vehicle_exit_count.items()):\n",
    "            y_pos = 150 + idx * 30\n",
    "            cv2.putText(frame, f\"{cls_name}: {count}\", (1710, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        # Draw the counting lines\n",
    "        cv2.line(frame, (entry_line['x1'], entry_line['y1']), (entry_line['x2'], entry_line['y2']), (0, 127, 255), 3)\n",
    "        cv2.line(frame, (exit_line['x1'], exit_line['y1']), (exit_line['x2'], exit_line['y2']), (0, 127, 255), 3)\n",
    "\n",
    "        # Display FPS\n",
    "        fps = 1 / (time.time() - start_time)\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (20, 52), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('YOLOv8 Vehicle Tracking', cv2.resize(frame, (1280, 720)))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break  # Exit when 'q' is pressed\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Print final counts\n",
    "    print(\"Vehicle Entry Counts:\", vehicle_entry_count)\n",
    "    print(\"Vehicle Exit Counts:\", vehicle_exit_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c18c2b3-3ce1-4d30-9256-cae86b4dcef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 cars, 450.1ms\n",
      "Speed: 6.3ms preprocess, 450.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 400.3ms\n",
      "Speed: 7.4ms preprocess, 400.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 338.8ms\n",
      "Speed: 7.4ms preprocess, 338.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 332.8ms\n",
      "Speed: 6.4ms preprocess, 332.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 325.1ms\n",
      "Speed: 5.8ms preprocess, 325.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 338.8ms\n",
      "Speed: 8.4ms preprocess, 338.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 339.4ms\n",
      "Speed: 7.2ms preprocess, 339.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 320.2ms\n",
      "Speed: 1.0ms preprocess, 320.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 316.9ms\n",
      "Speed: 11.4ms preprocess, 316.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 321.3ms\n",
      "Speed: 2.8ms preprocess, 321.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 312.0ms\n",
      "Speed: 1.0ms preprocess, 312.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 315.5ms\n",
      "Speed: 1.0ms preprocess, 315.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 305.9ms\n",
      "Speed: 11.3ms preprocess, 305.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 305.9ms\n",
      "Speed: 6.3ms preprocess, 305.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 300.4ms\n",
      "Speed: 11.1ms preprocess, 300.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 307.8ms\n",
      "Speed: 4.4ms preprocess, 307.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 299.5ms\n",
      "Speed: 6.7ms preprocess, 299.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 309.9ms\n",
      "Speed: 4.3ms preprocess, 309.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 314.7ms\n",
      "Speed: 4.8ms preprocess, 314.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 322.2ms\n",
      "Speed: 5.0ms preprocess, 322.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 306.4ms\n",
      "Speed: 6.8ms preprocess, 306.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 298.3ms\n",
      "Speed: 4.5ms preprocess, 298.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 313.2ms\n",
      "Speed: 5.5ms preprocess, 313.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 303.4ms\n",
      "Speed: 5.7ms preprocess, 303.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 304.4ms\n",
      "Speed: 4.5ms preprocess, 304.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 309.5ms\n",
      "Speed: 5.3ms preprocess, 309.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 301.3ms\n",
      "Speed: 6.1ms preprocess, 301.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 317.3ms\n",
      "Speed: 5.2ms preprocess, 317.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 301.1ms\n",
      "Speed: 6.6ms preprocess, 301.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 301.3ms\n",
      "Speed: 8.1ms preprocess, 301.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 311.3ms\n",
      "Speed: 4.6ms preprocess, 311.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 305.2ms\n",
      "Speed: 6.5ms preprocess, 305.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 299.8ms\n",
      "Speed: 4.4ms preprocess, 299.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 302.1ms\n",
      "Speed: 8.4ms preprocess, 302.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 315.0ms\n",
      "Speed: 5.7ms preprocess, 315.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 302.1ms\n",
      "Speed: 5.4ms preprocess, 302.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 299.8ms\n",
      "Speed: 7.1ms preprocess, 299.8ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 309.2ms\n",
      "Speed: 6.6ms preprocess, 309.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 291.4ms\n",
      "Speed: 6.2ms preprocess, 291.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 290.7ms\n",
      "Speed: 5.8ms preprocess, 290.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 306.0ms\n",
      "Speed: 10.3ms preprocess, 306.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 306.0ms\n",
      "Speed: 4.3ms preprocess, 306.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 305.4ms\n",
      "Speed: 4.9ms preprocess, 305.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 294.3ms\n",
      "Speed: 6.5ms preprocess, 294.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 303.1ms\n",
      "Speed: 6.6ms preprocess, 303.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 293.0ms\n",
      "Speed: 6.6ms preprocess, 293.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 311.1ms\n",
      "Speed: 5.7ms preprocess, 311.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 333.7ms\n",
      "Speed: 5.3ms preprocess, 333.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 306.3ms\n",
      "Speed: 8.1ms preprocess, 306.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 303.0ms\n",
      "Speed: 6.5ms preprocess, 303.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trucks, 297.6ms\n",
      "Speed: 6.1ms preprocess, 297.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 296.5ms\n",
      "Speed: 6.0ms preprocess, 296.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trucks, 294.5ms\n",
      "Speed: 5.4ms preprocess, 294.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trucks, 298.8ms\n",
      "Speed: 6.5ms preprocess, 298.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 298.9ms\n",
      "Speed: 7.6ms preprocess, 298.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 311.3ms\n",
      "Speed: 5.6ms preprocess, 311.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 truck, 300.3ms\n",
      "Speed: 6.0ms preprocess, 300.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trucks, 295.5ms\n",
      "Speed: 7.1ms preprocess, 295.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 2 trucks, 493.2ms\n",
      "Speed: 5.9ms preprocess, 493.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 326.3ms\n",
      "Speed: 5.8ms preprocess, 326.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 297.0ms\n",
      "Speed: 7.0ms preprocess, 297.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 319.1ms\n",
      "Speed: 4.9ms preprocess, 319.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 302.5ms\n",
      "Speed: 5.6ms preprocess, 302.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 306.6ms\n",
      "Speed: 5.9ms preprocess, 306.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 310.1ms\n",
      "Speed: 4.1ms preprocess, 310.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 300.7ms\n",
      "Speed: 3.0ms preprocess, 300.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 309.7ms\n",
      "Speed: 6.0ms preprocess, 309.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 301.5ms\n",
      "Speed: 6.2ms preprocess, 301.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 307.0ms\n",
      "Speed: 5.9ms preprocess, 307.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 306.7ms\n",
      "Speed: 4.6ms preprocess, 306.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 299.8ms\n",
      "Speed: 5.1ms preprocess, 299.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 305.1ms\n",
      "Speed: 6.0ms preprocess, 305.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 301.2ms\n",
      "Speed: 10.5ms preprocess, 301.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 313.1ms\n",
      "Speed: 9.8ms preprocess, 313.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 309.9ms\n",
      "Speed: 5.2ms preprocess, 309.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 336.1ms\n",
      "Speed: 7.3ms preprocess, 336.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 321.2ms\n",
      "Speed: 6.3ms preprocess, 321.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 300.4ms\n",
      "Speed: 4.5ms preprocess, 300.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 297.3ms\n",
      "Speed: 5.0ms preprocess, 297.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 297.5ms\n",
      "Speed: 5.9ms preprocess, 297.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 302.8ms\n",
      "Speed: 5.8ms preprocess, 302.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 306.1ms\n",
      "Speed: 4.9ms preprocess, 306.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 313.0ms\n",
      "Speed: 4.6ms preprocess, 313.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 310.1ms\n",
      "Speed: 4.8ms preprocess, 310.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 308.9ms\n",
      "Speed: 4.4ms preprocess, 308.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 311.3ms\n",
      "Speed: 5.0ms preprocess, 311.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 300.3ms\n",
      "Speed: 6.1ms preprocess, 300.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 303.0ms\n",
      "Speed: 5.8ms preprocess, 303.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 301.2ms\n",
      "Speed: 4.3ms preprocess, 301.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 307.1ms\n",
      "Speed: 5.8ms preprocess, 307.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 1 truck, 302.3ms\n",
      "Speed: 5.4ms preprocess, 302.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 309.0ms\n",
      "Speed: 4.5ms preprocess, 309.0ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 313.0ms\n",
      "Speed: 4.0ms preprocess, 313.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 308.8ms\n",
      "Speed: 6.6ms preprocess, 308.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 313.3ms\n",
      "Speed: 4.4ms preprocess, 313.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 301.1ms\n",
      "Speed: 4.5ms preprocess, 301.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 301.8ms\n",
      "Speed: 6.0ms preprocess, 301.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 311.8ms\n",
      "Speed: 4.1ms preprocess, 311.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 307.6ms\n",
      "Speed: 6.7ms preprocess, 307.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 truck, 298.0ms\n",
      "Speed: 4.6ms preprocess, 298.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 truck, 315.7ms\n",
      "Speed: 5.1ms preprocess, 315.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 326.6ms\n",
      "Speed: 4.5ms preprocess, 326.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 329.7ms\n",
      "Speed: 5.6ms preprocess, 329.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 341.8ms\n",
      "Speed: 10.9ms preprocess, 341.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 310.9ms\n",
      "Speed: 5.4ms preprocess, 310.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 bus, 2 trucks, 314.6ms\n",
      "Speed: 5.8ms preprocess, 314.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 bus, 1 truck, 319.5ms\n",
      "Speed: 6.3ms preprocess, 319.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 bus, 1 truck, 314.1ms\n",
      "Speed: 5.6ms preprocess, 314.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 bus, 1 truck, 330.6ms\n",
      "Speed: 6.0ms preprocess, 330.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 bus, 2 trucks, 309.2ms\n",
      "Speed: 6.0ms preprocess, 309.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 313.8ms\n",
      "Speed: 6.4ms preprocess, 313.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 2 trucks, 311.5ms\n",
      "Speed: 7.1ms preprocess, 311.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Vehicle Entry Counts: {'bicycle': 0, 'car': 4, 'motorcycle': 0, 'bus': 0, 'truck': 0}\n",
      "Vehicle Exit Counts: {'bicycle': 0, 'car': 1, 'motorcycle': 0, 'bus': 0, 'truck': 0}\n"
     ]
    }
   ],
   "source": [
    "run_yolov8_tracking_with_counter('./highway.mp4', 'yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39d8ce9-5c72-4119-ae83-4a243528c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 + 1 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2b107-b41e-465c-9dbe-c56f671c8a20",
   "metadata": {},
   "source": [
    "## Dynmaic vehicle counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e58b4fa3-20c7-44b9-a32b-9ac3d46f607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2, time\n",
    "\n",
    "def run_yolov8_generalized_counter(video_source, model_path, counting_lines):\n",
    "    \"\"\"\n",
    "    Run vehicle detection, tracking, and counting using YOLOv8 with generalized counting lines.\n",
    "    Args:\n",
    "        video_source: Path to the video file or webcam index (e.g., 0 for default webcam).\n",
    "        model_path: Path to YOLOv8 model (e.g., \"yolov8n.pt\").\n",
    "        counting_lines: List of counting line configurations (e.g., entry/exit lines).\n",
    "    \"\"\"\n",
    "    # Load YOLOv8 model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # Open the video source\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "        print('Error: Unable to open video source.')\n",
    "        return\n",
    "\n",
    "    # Get original video resolution\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Original video resolution: {original_width}x{original_height}\")\n",
    "\n",
    "    # YOLOv8 resolution\n",
    "    yolo_width, yolo_height = 640, 384  # From YOLOv8 logs\n",
    "\n",
    "    # Scale counting lines to YOLOv8 resolution\n",
    "    scaled_lines = []\n",
    "    for line in counting_lines:\n",
    "        scaled_line = {\n",
    "            \"label\": line[\"label\"],\n",
    "            \"x1\": int(line[\"x1\"] * yolo_width / original_width),\n",
    "            \"y1\": int(line[\"y1\"] * yolo_height / original_height),\n",
    "            \"x2\": int(line[\"x2\"] * yolo_width / original_width),\n",
    "            \"y2\": int(line[\"y2\"] * yolo_height / original_height),\n",
    "            \"offset\": int(line[\"offset\"] * yolo_height / original_height),\n",
    "        }\n",
    "        scaled_lines.append(scaled_line)\n",
    "    print(f\"Scaled lines: {scaled_lines}\")\n",
    "\n",
    "    # Vehicle counters and helper variables\n",
    "    class_names = model.names\n",
    "    vehicle_class_ids = [1, 2, 3, 5, 7]  # IDs for bicycle, car, motorcycle, bus, truck\n",
    "    counters = {line[\"label\"]: {class_names[cls]: 0 for cls in vehicle_class_ids} for line in scaled_lines}\n",
    "    tracked_ids = {line[\"label\"]: [] for line in scaled_lines}  # Track IDs for each line\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit the loop if no more frames\n",
    "\n",
    "        start_time = time.time()  # Start timer for FPS calculation\n",
    "\n",
    "        # Resize frame to YOLOv8's input resolution\n",
    "        resized_frame = cv2.resize(frame, (yolo_width, yolo_height))\n",
    "\n",
    "        # Perform detection and tracking\n",
    "        results = model.track(resized_frame, persist=True, tracker=\"bytetrack.yaml\")  # Use built-in ByteTrack tracker\n",
    "\n",
    "        if results and results[0].boxes is not None:\n",
    "            for box in results[0].boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy.cpu().numpy().flatten())  # Bounding box coordinates\n",
    "                cls = int(box.cls.cpu().numpy().item())  # Class ID\n",
    "                track_id = int(box.id.cpu().numpy().item()) if box.id is not None else None\n",
    "                conf = box.conf.numpy().item()\n",
    "                \n",
    "                # Calculate the center of the bounding box\n",
    "                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "                # Check crossing for each scaled line\n",
    "                for line in scaled_lines:\n",
    "                    label, lx1, ly1, lx2, ly2, offset = line.values()\n",
    "                    if lx1 <= center_x <= lx2 and ly1 - offset <= center_y <= ly1 + offset:\n",
    "                        if track_id not in tracked_ids[label] and cls in vehicle_class_ids:\n",
    "                            counters[label][class_names[cls]] += 1\n",
    "                            tracked_ids[label].append(track_id)\n",
    "\n",
    "                # Draw bounding box\n",
    "                color = (0, 255, 0)\n",
    "                cv2.rectangle(resized_frame, (x1, y1), (x2, y2), color, 1)\n",
    "                #label = f\"ID: {track_id}, Class: {class_names[cls]}, Conf: {conf:.2f}\"\n",
    "                label = class_names[cls]\n",
    "                cv2.putText(resized_frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Draw scaled lines\n",
    "        for idx, line in enumerate(scaled_lines):\n",
    "            label, lx1, ly1, lx2, ly2, offset = line.values()\n",
    "\n",
    "            # Draw the counting line\n",
    "            cv2.line(resized_frame, (lx1, ly1), (lx2, ly2), (0, 127, 255), 3)\n",
    "\n",
    "        # Draw vertical counters for each line\n",
    "        x_start = 30  # Starting x position for the first column\n",
    "        x_offset = 200  # Horizontal distance between columns\n",
    "        y_start = 30  # Starting y position for rows\n",
    "        y_offset = 30  # Vertical spacing between rows\n",
    "\n",
    "        for col_idx, line in enumerate(scaled_lines):\n",
    "            label = line[\"label\"]\n",
    "            x_pos = x_start + col_idx * x_offset  # Calculate column position for this line\n",
    "\n",
    "            # Display the line label (e.g., \"Entry1 Counts\")\n",
    "            cv2.putText(\n",
    "                resized_frame, \n",
    "                f\"{label} Counts:\", \n",
    "                (x_pos, y_start), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5,  # Font scale\n",
    "                (255, 255, 255),  # White color\n",
    "                1  # Thickness\n",
    "            )\n",
    "\n",
    "            # Display each class count in a vertical list\n",
    "            for row_idx, (cls_name, count) in enumerate(counters[label].items()):\n",
    "                y_pos = y_start + (row_idx + 1) * y_offset  # Calculate row position\n",
    "                cv2.putText(\n",
    "                    resized_frame, \n",
    "                    f\"{cls_name}: {count}\", \n",
    "                    (x_pos, y_pos), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5,  # Font scale\n",
    "                    (255, 255, 255),  # White color\n",
    "                    1  # Thickness\n",
    "                )\n",
    "\n",
    "        # Display FPS\n",
    "        fps = 1 / (time.time() - start_time)\n",
    "        fps_text = f\"FPS: {fps:.2f}\"\n",
    "        cv2.putText(resized_frame, fps_text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Resize for display only\n",
    "        display_frame = cv2.resize(resized_frame, (original_width, original_height))  # Scale back for visualization\n",
    "        cv2.imshow(\"YOLOv8 Vehicle Tracking\", cv2.resize (display_frame, (960, 540)))\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    for label, counts in counters.items():\n",
    "        print(f\"{label} Counts:\", counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a15b86e-029d-41de-a5ec-3fdc83eada5d",
   "metadata": {},
   "source": [
    "### Testing our Dynamic counter\n",
    "#### creating a function to get the coordnates (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e006d9-b67e-497f-8465-630dbc7f23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_coordinates(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Left mouse button click\n",
    "        print(f\"Selected point: ({x}, {y})\")\n",
    "\n",
    "cap = cv2.VideoCapture('./highway2.mp4')\n",
    "count = 0\n",
    "while count < 6:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Frame\", cv2.resize (frame, (960, 540)))\n",
    "    if count == 3:\n",
    "        cv2.setMouseCallback(\"Frame\", get_coordinates)  # Attach the callback\n",
    "        cv2.waitKey(0)  # Wait for user to click\n",
    "    count +=1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b2c8bbf-d225-4ea3-be89-c8ed4422ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_lines = [\n",
    "    {\"label\": \"Entry1\", \"x1\": 469, \"y1\": 397, \"x2\": 814, \"y2\": 449, \"offset\": 20},\n",
    "    {\"label\": \"Entry2\", \"x1\": 1037, \"y1\": 424, \"x2\": 1431, \"y2\": 346, \"offset\": 20}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8783749d-6219-4e64-8598-0eb4ab9978fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original video resolution: 1920x1080\n",
      "Scaled lines: [{'label': 'Entry1', 'x1': 156, 'y1': 141, 'x2': 271, 'y2': 159, 'offset': 7}, {'label': 'Entry2', 'x1': 345, 'y1': 150, 'x2': 477, 'y2': 123, 'offset': 7}]\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 443.8ms\n",
      "Speed: 4.2ms preprocess, 443.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 439.8ms\n",
      "Speed: 2.0ms preprocess, 439.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 353.6ms\n",
      "Speed: 4.2ms preprocess, 353.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 349.3ms\n",
      "Speed: 5.3ms preprocess, 349.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 328.9ms\n",
      "Speed: 1.0ms preprocess, 328.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 337.9ms\n",
      "Speed: 10.8ms preprocess, 337.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 323.2ms\n",
      "Speed: 2.0ms preprocess, 323.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 324.4ms\n",
      "Speed: 15.3ms preprocess, 324.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 328.3ms\n",
      "Speed: 0.0ms preprocess, 328.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 314.9ms\n",
      "Speed: 0.0ms preprocess, 314.9ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 309.4ms\n",
      "Speed: 1.0ms preprocess, 309.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 311.2ms\n",
      "Speed: 1.0ms preprocess, 311.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 308.9ms\n",
      "Speed: 1.0ms preprocess, 308.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 296.7ms\n",
      "Speed: 5.1ms preprocess, 296.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 302.5ms\n",
      "Speed: 1.0ms preprocess, 302.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 297.2ms\n",
      "Speed: 5.1ms preprocess, 297.2ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 289.2ms\n",
      "Speed: 3.3ms preprocess, 289.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 276.7ms\n",
      "Speed: 3.6ms preprocess, 276.7ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 291.8ms\n",
      "Speed: 3.7ms preprocess, 291.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 284.9ms\n",
      "Speed: 5.1ms preprocess, 284.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 293.1ms\n",
      "Speed: 5.6ms preprocess, 293.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 301.7ms\n",
      "Speed: 4.7ms preprocess, 301.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 283.7ms\n",
      "Speed: 4.1ms preprocess, 283.7ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 282.9ms\n",
      "Speed: 3.5ms preprocess, 282.9ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 296.7ms\n",
      "Speed: 3.8ms preprocess, 296.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 293.3ms\n",
      "Speed: 4.7ms preprocess, 293.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 car, 6 trains, 297.3ms\n",
      "Speed: 3.2ms preprocess, 297.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 293.7ms\n",
      "Speed: 4.2ms preprocess, 293.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 297.0ms\n",
      "Speed: 3.4ms preprocess, 297.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 288.5ms\n",
      "Speed: 5.4ms preprocess, 288.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 285.2ms\n",
      "Speed: 3.9ms preprocess, 285.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 trains, 300.7ms\n",
      "Speed: 4.5ms preprocess, 300.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 trains, 315.6ms\n",
      "Speed: 4.2ms preprocess, 315.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 trains, 284.1ms\n",
      "Speed: 3.0ms preprocess, 284.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 2 trains, 295.2ms\n",
      "Speed: 3.7ms preprocess, 295.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 292.0ms\n",
      "Speed: 2.0ms preprocess, 292.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 280.8ms\n",
      "Speed: 6.2ms preprocess, 280.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 286.6ms\n",
      "Speed: 4.0ms preprocess, 286.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 298.2ms\n",
      "Speed: 4.9ms preprocess, 298.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 300.7ms\n",
      "Speed: 4.3ms preprocess, 300.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 296.3ms\n",
      "Speed: 3.6ms preprocess, 296.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 297.6ms\n",
      "Speed: 3.9ms preprocess, 297.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 car, 1 train, 303.9ms\n",
      "Speed: 3.8ms preprocess, 303.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 506.9ms\n",
      "Speed: 3.4ms preprocess, 506.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 317.0ms\n",
      "Speed: 3.4ms preprocess, 317.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 cars, 1 train, 302.0ms\n",
      "Speed: 4.0ms preprocess, 302.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 297.6ms\n",
      "Speed: 4.2ms preprocess, 297.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 293.2ms\n",
      "Speed: 3.4ms preprocess, 293.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 286.3ms\n",
      "Speed: 3.9ms preprocess, 286.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 cars, 1 train, 288.0ms\n",
      "Speed: 3.5ms preprocess, 288.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 288.8ms\n",
      "Speed: 4.3ms preprocess, 288.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 298.0ms\n",
      "Speed: 3.5ms preprocess, 298.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 304.2ms\n",
      "Speed: 3.9ms preprocess, 304.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 292.1ms\n",
      "Speed: 4.4ms preprocess, 292.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 290.4ms\n",
      "Speed: 4.7ms preprocess, 290.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 335.9ms\n",
      "Speed: 4.4ms preprocess, 335.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 286.5ms\n",
      "Speed: 5.1ms preprocess, 286.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 294.0ms\n",
      "Speed: 4.1ms preprocess, 294.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 283.8ms\n",
      "Speed: 2.8ms preprocess, 283.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 292.9ms\n",
      "Speed: 4.0ms preprocess, 292.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 314.5ms\n",
      "Speed: 3.8ms preprocess, 314.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 280.3ms\n",
      "Speed: 3.7ms preprocess, 280.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 290.8ms\n",
      "Speed: 3.7ms preprocess, 290.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Entry1 Counts: {'bicycle': 0, 'car': 2, 'motorcycle': 0, 'bus': 0, 'truck': 0}\n",
      "Entry2 Counts: {'bicycle': 0, 'car': 1, 'motorcycle': 0, 'bus': 0, 'truck': 0}\n"
     ]
    }
   ],
   "source": [
    "run_yolov8_generalized_counter(\"highway3.mp4\", \"yolov8s.pt\", counting_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c45683-be97-41ec-842d-aaa6f5484f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ce1421f-9fa1-4a4c-8555-ac14d18c8bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3bff1-86a3-4b32-b66e-d00bbcb014a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a4284-59d3-4b87-ae51-8ef53bd951bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63b826-fb0e-43b8-89c3-7dad973152d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0c6c8-689e-4b52-9963-ea53abf662b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e080573-d8fe-43b3-a37b-d9e23a0b81ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d63dc-6a83-4e6a-aa8d-542f7fd56bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa99eb3-a274-4026-aaaa-5695ed517ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolov8-cpu-env)",
   "language": "python",
   "name": "yolov8-cpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
